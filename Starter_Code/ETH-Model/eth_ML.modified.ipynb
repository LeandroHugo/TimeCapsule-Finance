{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d4dea66-64af-4a4a-bfde-21584767e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import plotly.graph_objects as go  # Using plotly.graph_objects for more control over the plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd0cea-ad5e-4412-819e-c206bd6ef293",
   "metadata": {},
   "source": [
    "## Import/clean Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70989193-2758-47b3-90a8-6e188de54241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-27</th>\n",
       "      <td>464.009003</td>\n",
       "      <td>473.221985</td>\n",
       "      <td>458.290985</td>\n",
       "      <td>469.665985</td>\n",
       "      <td>469.665985</td>\n",
       "      <td>1.734260e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28</th>\n",
       "      <td>469.678009</td>\n",
       "      <td>471.593994</td>\n",
       "      <td>462.989014</td>\n",
       "      <td>466.898010</td>\n",
       "      <td>466.898010</td>\n",
       "      <td>1.531890e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-29</th>\n",
       "      <td>466.915009</td>\n",
       "      <td>470.355988</td>\n",
       "      <td>462.712006</td>\n",
       "      <td>466.665009</td>\n",
       "      <td>466.665009</td>\n",
       "      <td>1.631910e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30</th>\n",
       "      <td>466.826996</td>\n",
       "      <td>467.951996</td>\n",
       "      <td>448.640991</td>\n",
       "      <td>457.080994</td>\n",
       "      <td>457.080994</td>\n",
       "      <td>2.141590e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>457.244995</td>\n",
       "      <td>457.244995</td>\n",
       "      <td>430.444000</td>\n",
       "      <td>433.867004</td>\n",
       "      <td>433.867004</td>\n",
       "      <td>1.820680e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-07-27  464.009003  473.221985  458.290985  469.665985  469.665985   \n",
       "2018-07-28  469.678009  471.593994  462.989014  466.898010  466.898010   \n",
       "2018-07-29  466.915009  470.355988  462.712006  466.665009  466.665009   \n",
       "2018-07-30  466.826996  467.951996  448.640991  457.080994  457.080994   \n",
       "2018-07-31  457.244995  457.244995  430.444000  433.867004  433.867004   \n",
       "\n",
       "                  Volume  \n",
       "Date                      \n",
       "2018-07-27  1.734260e+09  \n",
       "2018-07-28  1.531890e+09  \n",
       "2018-07-29  1.631910e+09  \n",
       "2018-07-30  2.141590e+09  \n",
       "2018-07-31  1.820680e+09  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected Data Loading & Preprocessing steps\n",
    "\n",
    "# 1. Data Loading & Preprocessing\n",
    "eth_data_corrected = pd.read_csv('Eth_USD_18_23.csv')\n",
    "eth_data_corrected['Date'] = pd.to_datetime(eth_data_corrected['Date'])\n",
    "eth_data_corrected.set_index('Date', inplace=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "eth_data_corrected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "597a4628-477d-43d6-964f-94031a427c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the corrected dataframe 'eth_data_corrected' in place of 'eth_data'\n",
    "eth_close_corrected = eth_data_corrected[['Close']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864c8f28-406a-410b-941c-9cf1fe8f56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Engineering\n",
    "# Calculate Rolling 30-day and 10-day Averages\n",
    "eth_close_corrected['RollingAvg_30'] = eth_close_corrected['Close'].rolling(window=30).mean()\n",
    "eth_close_corrected['RollingAvg_10'] = eth_close_corrected['Close'].rolling(window=10).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43729bcf-90b6-4f9e-8699-f895ace6c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns \n",
    "eth_close_corrected['Daily_PctChange'] = eth_close_corrected['Close'].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c7ab3fd-2c3a-4885-94d2-244f3f2455f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage changes for rolling averages\n",
    "eth_close_corrected['10R_PctChange'] = eth_close_corrected['RollingAvg_10'].pct_change()\n",
    "eth_close_corrected['30R_PctChange'] = eth_close_corrected['RollingAvg_30'].pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5e3d330-4d6a-4ae0-91db-33aa034820a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_close_corrected.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6e64157-21fb-414b-bc39-629efa5d1c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2018-08-26    0.0\n",
       "2018-08-27    NaN\n",
       "2018-08-28    NaN\n",
       "2018-08-29    0.0\n",
       "2018-08-30    NaN\n",
       "Name: Target_Complex, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefining the assign_target function\n",
    "\n",
    "def assign_target(row):\n",
    "    if row['Daily_PctChange'] >= 0 and row['10R_PctChange'] >= 0 and row['30R_PctChange'] >= 0:\n",
    "        return 1.0\n",
    "    elif row['Daily_PctChange'] < 0 and row['10R_PctChange'] < 0 and row['30R_PctChange'] < 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Applying the function again to create the 'Target_Complex' column\n",
    "eth_close_corrected['Target_Complex'] = eth_close_corrected.apply(lambda row: assign_target(row), axis=1)\n",
    "\n",
    "# Verify the 'Target_Complex' column\n",
    "eth_close_corrected['Target_Complex'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfc357c6-c9ed-4a69-9412-b7308439d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Target Definition\n",
    "# From eth_ML.ipynb\n",
    "eth_close_corrected['Target_Complex'] = eth_close_corrected.apply(lambda row: assign_target(row), axis=1)\n",
    "\n",
    "# From eth_ML2.ipynb\n",
    "eth_close_corrected['Target_Simple'] = np.where(eth_close_corrected['Daily_PctChange'] >= 0, 1.0, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05c610a9-d6a8-4322-84a4-61b190d13502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Splitting and rest of the steps (as provided in the original code)\n",
    "# For Target_Complex\n",
    "X_complex_corrected = eth_close_corrected.drop(columns=['Target_Complex', 'Target_Simple'])\n",
    "y_complex_corrected = eth_close_corrected['Target_Complex']\n",
    "X_train_complex_corrected, X_test_complex_corrected, y_train_complex_corrected, y_test_complex_corrected = train_test_split(X_complex_corrected, y_complex_corrected, random_state=1)\n",
    "\n",
    "# For Target_Simple\n",
    "X_simple_corrected = eth_close_corrected.drop(columns=['Target_Complex', 'Target_Simple'])\n",
    "y_simple_corrected = eth_close_corrected['Target_Simple']\n",
    "X_train_simple_corrected, X_test_simple_corrected, y_train_simple_corrected, y_test_simple_corrected = train_test_split(X_simple_corrected, y_simple_corrected, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0c19487-6929-42a2-a481-7c138430960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Scaling\n",
    "scaler_complex_corrected = StandardScaler().fit(X_train_complex_corrected)\n",
    "X_train_complex_scaled_corrected = scaler_complex_corrected.transform(X_train_complex_corrected)\n",
    "X_test_complex_scaled_corrected = scaler_complex_corrected.transform(X_test_complex_corrected)\n",
    "\n",
    "scaler_simple_corrected = StandardScaler().fit(X_train_simple_corrected)\n",
    "X_train_simple_scaled_corrected = scaler_simple_corrected.transform(X_train_simple_corrected)\n",
    "X_test_simple_scaled_corrected = scaler_simple_corrected.transform(X_test_simple_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dcf6d96-b655-4a26-9dff-ac8459b16094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Creation & Training\n",
    "# rf_model_complex_corrected = RandomForestClassifier(n_estimators=500, random_state=1).fit(X_train_complex_scaled_corrected, y_train_complex_corrected)\n",
    "# rf_model_simple_corrected = RandomForestClassifier(n_estimators=500, random_state=1).fit(X_train_simple_scaled_corrected, y_train_simple_corrected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2fb03",
   "metadata": {},
   "source": [
    "The error indicates that there are NaN values in the target column y_train_complex_corrected, which is the 'Target_Complex' column. The RandomForestClassifier cannot handle NaN values in the target variable.\n",
    "\n",
    "The NaN values arise from the assign_target function, where we assigned a value of np.nan when conditions for neither upward nor downward trend were met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc7b6b0a-dbe8-46d9-9ea6-638f977b20c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows with NaN values in the 'Target_Complex' column\n",
    "eth_close_corrected.dropna(subset=['Target_Complex'], inplace=True)\n",
    "\n",
    "# Splitting the data again\n",
    "X_complex_corrected = eth_close_corrected.drop(columns=['Target_Complex', 'Target_Simple'])\n",
    "y_complex_corrected = eth_close_corrected['Target_Complex']\n",
    "\n",
    "X_train_complex_corrected, X_test_complex_corrected, y_train_complex_corrected, y_test_complex_corrected = train_test_split(X_complex_corrected, y_complex_corrected, random_state=1)\n",
    "\n",
    "# Scaling the data again\n",
    "scaler_complex_corrected = StandardScaler().fit(X_train_complex_corrected)\n",
    "X_train_complex_scaled_corrected = scaler_complex_corrected.transform(X_train_complex_corrected)\n",
    "X_test_complex_scaled_corrected = scaler_complex_corrected.transform(X_test_complex_corrected)\n",
    "\n",
    "# Training the model again\n",
    "rf_model_complex_corrected = RandomForestClassifier(n_estimators=500, random_state=1).fit(X_train_complex_scaled_corrected, y_train_complex_corrected)\n",
    "\n",
    "# Checking the model's training accuracy as a quick verification\n",
    "training_accuracy = rf_model_complex_corrected.score(X_train_complex_scaled_corrected, y_train_complex_corrected)\n",
    "training_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4d4c093d-cd1e-469a-a87f-6be28758fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Creation & Training\n",
    "rf_model_complex_corrected = RandomForestClassifier(n_estimators=500, random_state=1).fit(X_train_complex_scaled_corrected, y_train_complex_corrected)\n",
    "rf_model_simple_corrected = RandomForestClassifier(n_estimators=500, random_state=1).fit(X_train_simple_scaled_corrected, y_train_simple_corrected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9dc08e0-9244-46be-b22a-92111d1bb132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    Predicted 0 (Complex)  Predicted 1 (Complex)\n",
       " Actual 0 (Complex)                     83                      0\n",
       " Actual 1 (Complex)                      0                    107,\n",
       " 1.0,\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00        83\\n         1.0       1.00      1.00      1.00       107\\n\\n    accuracy                           1.00       190\\n   macro avg       1.00      1.00      1.00       190\\nweighted avg       1.00      1.00      1.00       190\\n',\n",
       "                    Predicted 0 (Simple)  Predicted 1 (Simple)\n",
       " Actual 0 (Simple)                   214                     0\n",
       " Actual 1 (Simple)                     0                   235,\n",
       " 1.0,\n",
       " '              precision    recall  f1-score   support\\n\\n         0.0       1.00      1.00      1.00       214\\n         1.0       1.00      1.00      1.00       235\\n\\n    accuracy                           1.00       449\\n   macro avg       1.00      1.00      1.00       449\\nweighted avg       1.00      1.00      1.00       449\\n')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Model Evaluation\n",
    "predictions_complex_corrected = rf_model_complex_corrected.predict(X_test_complex_scaled_corrected)\n",
    "predictions_simple_corrected = rf_model_simple_corrected.predict(X_test_simple_scaled_corrected)\n",
    "\n",
    "cm_complex_corrected = confusion_matrix(y_test_complex_corrected, predictions_complex_corrected)\n",
    "cm_simple_corrected = confusion_matrix(y_test_simple_corrected, predictions_simple_corrected)\n",
    "\n",
    "acc_score_complex_corrected = accuracy_score(y_test_complex_corrected, predictions_complex_corrected)\n",
    "acc_score_simple_corrected = accuracy_score(y_test_simple_corrected, predictions_simple_corrected)\n",
    "\n",
    "class_report_complex_corrected = classification_report(y_test_complex_corrected, predictions_complex_corrected)\n",
    "class_report_simple_corrected = classification_report(y_test_simple_corrected, predictions_simple_corrected)\n",
    "\n",
    "cm_complex_df_corrected = pd.DataFrame(cm_complex_corrected, index=[\"Actual 0 (Complex)\", \"Actual 1 (Complex)\"], columns=[\"Predicted 0 (Complex)\", \"Predicted 1 (Complex)\"])\n",
    "cm_simple_df_corrected = pd.DataFrame(cm_simple_corrected, index=[\"Actual 0 (Simple)\", \"Actual 1 (Simple)\"], columns=[\"Predicted 0 (Simple)\", \"Predicted 1 (Simple)\"])\n",
    "\n",
    "cm_complex_df_corrected, acc_score_complex_corrected, class_report_complex_corrected, cm_simple_df_corrected, acc_score_simple_corrected, class_report_simple_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eed81b-f856-454a-89f5-00c138114055",
   "metadata": {},
   "source": [
    "Model with 'Target_Complex':\n",
    "Confusion Matrix:\n",
    "\n",
    "Predicted 0 (Downward Trend) and Actual 0: 199\n",
    "Predicted 1 (Upward Trend) and Actual 1: 250\n",
    "No misclassifications.\n",
    "Accuracy Score: 100% (1.0)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "Precision, Recall, and F1-score are all 100% for both classes.\n",
    "Model with 'Target_Simple':\n",
    "Confusion Matrix:\n",
    "\n",
    "Predicted 0 (Downward Trend) and Actual 0: 214\n",
    "Predicted 1 (Upward Trend) and Actual 1: 235\n",
    "No misclassifications.\n",
    "Accuracy Score: 100% (1.0)\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "Precision, Recall, and F1-score are all 100% for both classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
